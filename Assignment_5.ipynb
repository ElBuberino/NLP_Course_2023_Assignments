{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://communications.univie.ac.at/fileadmin/_processed_/csm_Uni_Logo_2016_2f47aacf37.jpg\" \n",
    "     alt=\"Logo Universität Wien\" \n",
    "     width=\"200\"/>\n",
    "\n",
    "# Practical Machine Learning for Natural Language Processing - 2023 SS  \n",
    "\n",
    "### Assigment 1 - Python for Poets  \n",
    "\n",
    "This assigment is an adaptation for Python of the original exercise [\"Unix for Poets\"](https://www.cs.upc.edu/~padro/Unixforpoets.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/accou/OneDrive/Dokumente/GitHub/Python_Course/Data/txt/nyt_200811.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will solve the following exercises using **Pure Python**  \n",
    "### (only packages \"string\" and \"re\" are allowed).  \n",
    "\n",
    "1. Count words in a text  \n",
    "2. Sort a list of words in various ways  \n",
    "   • ascii order   \n",
    "   • \"rhyming\" order   \n",
    "3. Extract useful info for a dictionary  \n",
    "4. Compute ngram statistics  \n",
    "5. Make a Concordance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Count words in a text\n",
    "\n",
    "a. Output a list of words in the file along with their frequency counts (ignoring case).   \n",
    "a. Count how many unique words there are (ignoring case).    \n",
    "c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "import string\n",
    "# Create list of lower-case words\n",
    "list_of_words = text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "# Create dictionary of word (key) and frequency (value))\n",
    "freq_dic = {}\n",
    "for word in list_of_words:\n",
    "    if word in freq_dic:\n",
    "        freq_dic[word] += 1\n",
    "    else:\n",
    "        freq_dic[word] = 1\n",
    "# print dictionary\n",
    "for word, freq in freq_dic.items():\n",
    "    print(f'{word}: {freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "# Count number of words in sets (unique words)\n",
    "len(set(text.translate(str.maketrans('', '', string.punctuation)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "\"\"\"y is considered as a consonant in this exercise\"\"\"\n",
    "import re\n",
    "\n",
    "# Define regular expression to match vowels\n",
    "vowel_pattern = re.compile('[aeiou]+')\n",
    "\n",
    "# Initialize dictionary to store the frequency of vowel sequences\n",
    "vowel_freq = {}\n",
    "\n",
    "# Iterate over each word\n",
    "for word in list_of_words:\n",
    "    # Find all vowel sequences\n",
    "    vowel_matches = vowel_pattern.findall(word)\n",
    "    # Iterate over each vowel sequence\n",
    "    for i in range(len(vowel_matches)):\n",
    "        for j in range(i + 1, len(vowel_matches) + 1):\n",
    "            # Get current vowel sequence\n",
    "            vowel_seq = ''.join(vowel_matches[i:j])\n",
    "            # Increment frequency of vowel sequence\n",
    "            if vowel_seq in vowel_freq:\n",
    "                vowel_freq[vowel_seq] += 1\n",
    "            else:\n",
    "                vowel_freq[vowel_seq] = 1\n",
    "\n",
    "# Print dictionary\n",
    "for vowel_seq, freq in vowel_freq.items():\n",
    "    print(f'{vowel_seq}: {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sorting and reversing lines of text\n",
    "\n",
    "a. Sort each line alphabetically (ignoring case).  \n",
    "b. Sort in numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  \n",
    "c. Alphabetically reverse sort (ignoring case).  \n",
    "d. Sort in reverse numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "# Split lines\n",
    "lines = text.translate(str.maketrans('', '', string.punctuation)).translate(str.maketrans('', '', string.punctuation)).splitlines()\n",
    "# Remove empty lines\n",
    "strip_lines = [line for line in lines if line.strip()]\n",
    "# Sort character in each line alphabetically\n",
    "sorted_alpha = [''.join(sorted(line, key=str.lower)) for line in strip_lines]\n",
    "# Remove whitespace\n",
    "sorted_alpha_final = [line.strip() for line in sorted_alpha]\n",
    "# Print sorted list\n",
    "sorted_alpha_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "# Order list numercically (default key)\n",
    "# Split lines\n",
    "lines = text.translate(str.maketrans('', '', string.punctuation)).translate(str.maketrans('', '', string.punctuation)).splitlines()\n",
    "# Remove empty lines\n",
    "strip_lines = [line for line in lines if line.strip()]\n",
    "# Sort character in each line alphabetically\n",
    "sorted_ascii = [''.join(sorted(line)) for line in strip_lines]\n",
    "# Remove whitespace\n",
    "sorted_ascii_final = [line.strip() for line in sorted_ascii]\n",
    "# Print sorted list\n",
    "sorted_ascii_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "# Step through list from last to first index\n",
    "sorted_alpha_final_reversed = [line[::-1] for line in sorted_alpha_final] \n",
    "# Print sorted list\n",
    "sorted_alpha_final_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)\n",
    "# Step through list from last to first index\n",
    "sorted_ascii_reversed = [line[::-1] for line in sorted_ascii_final]\n",
    "# Print sorted list\n",
    "sorted_ascii_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Computing basic statistics\n",
    "\n",
    "a. Find the 50 most common words  \n",
    "b. Find the words in the NYT that end in \"zz\"  \n",
    "c. Count the lines, the words, and the characters  \n",
    "d. How many all uppercase words are there in this NYT file?  \n",
    "e, How many 4-letter words?  \n",
    "f. How many different words are there with no vowels?  \n",
    "g. **tricky:** How many “1 syllable” words are there?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) \n",
    "# Sort freq_dic with respect to values, and reverse sorting order\n",
    "sorted_freq = sorted(freq_dic.items(),  key = lambda x: x[1], reverse = True)\n",
    "# Print top 50 words\n",
    "for key, value in sorted_freq[0:50]:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "# Find the words in the NYT that end in \"zz\" (similar to exercise 1a)\n",
    "zz_dic = {}\n",
    "for word in list_of_words:\n",
    "    # use 'string.endswith' to find words that end with zz\n",
    "    if word.endswith(\"zz\"):\n",
    "        if word in zz_dic:\n",
    "            zz_dic[word] += 1\n",
    "        else:\n",
    "            zz_dic[word] = 1\n",
    "# Print dictionary \n",
    "for word, freq in zz_dic.items():\n",
    "    print(f'{word}: {freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "# Number of lines\n",
    "print(\"Count lines:\", len(text.splitlines()))\n",
    "# Number of words:\n",
    "word_list = len(text.translate(str.maketrans('', '', string.punctuation)).split())\n",
    "print(\"Count words:\", word_list)\n",
    "# Number of characters\n",
    "print(\"Count characters:\", len(list(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)\n",
    "# Remove digits from list of words\n",
    "all_words = text.translate(str.maketrans('', '', string.punctuation)).translate(str.maketrans('', '', string.digits)).split()\n",
    "# Count upper case words\n",
    "count_u = 0\n",
    "for word in all_words:\n",
    "    if word.isupper():\n",
    "        count_u += 1\n",
    "print('The number of uppercase words is', count_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# e) \n",
    "# Count 4-letter words\n",
    "count_4 = 0\n",
    "for word in all_words:\n",
    "    if len(word) == 4:\n",
    "        count_4 += 1\n",
    "\n",
    "print(f'There are {count_4} 4-letter words in the text file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f)\n",
    "\"\"\"y is considered as a consonant\"\"\"\n",
    "no_vowel_list = []\n",
    "count = 0\n",
    "# Take vowel_freq dictionary from exercise 1c\n",
    "vowel_seq = list(vowel_freq.keys())\n",
    "# Iterate over list of words\n",
    "for word in list_of_words:\n",
    "    # Set flag to false\n",
    "    found_vowel_seq = False\n",
    "    # Iterate over keys of vowel_seq dictionary\n",
    "    for seq in vowel_seq:\n",
    "        # If vowel sequence is in word, set flag to true and break\n",
    "        if seq in word:\n",
    "            found_vowel_seq = True\n",
    "            break\n",
    "    # if no vowel sequence was found, increase count by 1 \n",
    "    if not found_vowel_seq:\n",
    "        count += 1        \n",
    "\n",
    "print(f'There are {count} words without vowels in the text file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g)\n",
    "# Idea: Count the number of words with only one vowel\n",
    "count = 0\n",
    "for word in all_words:\n",
    "    # Count the number of vowels in the word by summing \n",
    "    num_vowels = sum(1 for letter in word if letter in 'aeiouAEIOU')\n",
    "    if num_vowels == 1:\n",
    "        # If the word has only one vowel, it's a 1-syllable word\n",
    "        count += 1\n",
    "\n",
    "# Print the result\n",
    "print(f'There are {count} words with one syllable in the text file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compute ngrams  \n",
    "\n",
    "a. Find the 10 most common bigrams (2 words)\n",
    "b. Find the 10 most common trigrams (3 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "# Compute bigrams by matching all adjacent words\n",
    "bigrams = [w1 + ' ' + w2 for w1, w2 in zip(list_of_words, list_of_words[1:])]\n",
    "# Create dictionary of bigrams and their frequencies\n",
    "bigram_dic = {}\n",
    "for word in bigrams:\n",
    "    if word in bigram_dic:\n",
    "        bigram_dic[word] += 1\n",
    "    else:\n",
    "        bigram_dic[word] = 1\n",
    "# Sort dictionary with respect to values, and reverse sorting order\n",
    "bigram_freq = sorted(bigram_dic.items(), key = lambda x: x[1], reverse = True)\n",
    "# Print top 10 bigrams\n",
    "for key, value in bigram_freq[0:10]:\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "# Compute trigrams by matching all adjacent words\n",
    "trigrams = [w1 + ' ' + w2 + ' ' + w3 for w1, w2, w3 in zip(list_of_words, list_of_words[1:], list_of_words[2:])]\n",
    "# Create dictionary of trigrams and their frequencies\n",
    "trigram_dic = {}\n",
    "for word in trigrams:\n",
    "    if word in trigram_dic:\n",
    "        trigram_dic[word] += 1\n",
    "    else:\n",
    "        trigram_dic[word] = 1\n",
    "# Sort dictionary with respect to values, and reverse sorting order\n",
    "trigram_freq = sorted(trigram_dic.items(), key = lambda x: x[1], reverse = True)\n",
    "# Print top 10 trigrams\n",
    "for key, value in trigram_freq[0:10]:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Make a Concordance\n",
    "\n",
    "a. Create a concordance display for an arbitrary word. See the example below  \n",
    "\n",
    "![](../../Data/figs/Sample-concordance-lines-of-actually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concordance(term, term_list):\n",
    "    # Create dictionary for concordances\n",
    "    concordance = {}\n",
    "    # Key = word, value = index of word\n",
    "    for i, word in enumerate(term_list):\n",
    "        # If word is not yet in concordance dictionary\n",
    "        if word not in concordance:\n",
    "            # Create empty list for word\n",
    "            concordance[word] = []\n",
    "        # Append index to list to store all indices of this key as values\n",
    "        concordance[word].append(i)\n",
    "\n",
    "    # Print the condordance\n",
    "    for word in concordance:\n",
    "        # Retrieve list of indices\n",
    "        indices = concordance[word]\n",
    "        # Create list to store context of term\n",
    "        context = []\n",
    "        # Iterate over indices\n",
    "        for i in indices:\n",
    "            # Start index = current index - 2 (minimally 0)\n",
    "            start_index = max(0, i-2)\n",
    "            # End index = current index + 2 (not longer than than term_list)\n",
    "            end_index = min(len(term_list), i+3)\n",
    "            # Slice context words from term_list and store them in the list 'context'\n",
    "            context.append(' '.join(term_list[start_index:end_index]))\n",
    "        # Print concordance when the searched term matches the word in the for loop\n",
    "        if word == term:\n",
    "            print(f\" {word}:\\n\\n\", '\\n '.join(context))\n",
    "\n",
    "# Call function and enter 'word' and 'list'\n",
    "get_concordance('million', list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit – Secret Message\n",
    "+ The answers to the extra credit exercises will reveal a secret message.  \n",
    "+ We will be working with the following text file for these exercises:  \n",
    "[Link to Text](https://web.stanford.edu/class/cs124/lec/secret_ec.txt)  \n",
    "(No starter code in the Extra Credit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 1\n",
    "• Find the 2 most common words in secret_ec.txt containing the letter e.  \n",
    "• Your answer will correspond to the first two words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 2\n",
    "• Find the 2 most common bigrams in secret_ec.txt where the second word in the bigram ends with a consonant.  \n",
    "• Your answer will correspond to the next four words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 3\n",
    "• Find all 5-letter-long words that only appear once in secret_ec.txt.   \n",
    "• Concatenate your result. This will be the final word of the secret message.  \n",
    "\n",
    "What is the secret message?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
